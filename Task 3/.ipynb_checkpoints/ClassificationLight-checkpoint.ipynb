{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from keras.optimizers import Adagrad\n",
    "from tslearn.shapelets import ShapeletModel\n",
    "from tslearn.shapelets import grabocka_params_to_shapelet_size_dict\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, Activation, Conv1D, BatchNormalization\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:51:00</th>\n",
       "      <td>1</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:51:00</th>\n",
       "      <td>2</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:53:00</th>\n",
       "      <td>3</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:54:00</th>\n",
       "      <td>4</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 17:55:00</th>\n",
       "      <td>5</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
       "date                                                                           \n",
       "2015-02-04 17:51:00   1        23.18   27.2720  426.0  721.25       0.004793   \n",
       "2015-02-04 17:51:00   2        23.15   27.2675  429.5  714.00       0.004783   \n",
       "2015-02-04 17:53:00   3        23.15   27.2450  426.0  713.50       0.004779   \n",
       "2015-02-04 17:54:00   4        23.15   27.2000  426.0  708.25       0.004772   \n",
       "2015-02-04 17:55:00   5        23.10   27.2000  426.0  704.50       0.004757   \n",
       "\n",
       "                     Occupancy  \n",
       "date                            \n",
       "2015-02-04 17:51:00          1  \n",
       "2015-02-04 17:51:00          1  \n",
       "2015-02-04 17:53:00          1  \n",
       "2015-02-04 17:54:00          1  \n",
       "2015-02-04 17:55:00          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateparse = lambda dates: pd.datetime.strptime(dates, '%d/%m/%y %H:%M')\n",
    "df = pd.read_csv('../datatraining.csv', sep=\";\", parse_dates=True, index_col='date', date_parser=dateparse)\n",
    "test = pd.read_csv('../datatest.csv', sep=\";\", parse_dates=True, index_col='date', date_parser=dateparse)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('HumidityRatio', axis=1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [col for col in df.columns if \n",
    "              #col == 'IsWorkDay' \n",
    "              #or col == 'Hour' \n",
    "              col == 'Light'\n",
    "              #or col == 'IsWorkHour'\n",
    "              #or col == 'Temperature'\n",
    "              #or col == 'date'\n",
    "              #or col == 'Humidity'\n",
    "              #or col == 'CO2'\n",
    "              #or col == 'HumidityRatio'\n",
    "             ]\n",
    "X_train = df[attributes].values\n",
    "y_train = df['Occupancy']\n",
    "\n",
    "attributes = [col for col in df.columns if \n",
    "              #col == 'IsWorkDay' \n",
    "              #or col == 'Hour' \n",
    "              col == 'Light'\n",
    "              #or col == 'IsWorkHour'\n",
    "              #or col == 'Temperature'\n",
    "              #or col == 'date'\n",
    "              #or col == 'Humidity'\n",
    "              #or col == 'CO2'\n",
    "              #or col == 'HumidityRatio'\n",
    "             ]\n",
    "X_test = test[attributes].values\n",
    "y_test = test['Occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[426. ],\n",
       "       [429.5],\n",
       "       [426. ],\n",
       "       ...,\n",
       "       [433. ],\n",
       "       [433. ],\n",
       "       [447. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_cnn(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=100, kernel_size=1, activation='relu', input_shape=(n_timesteps, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=150, kernel_size=1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=200, kernel_size=1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  1\n",
      "N. LABELS:  2\n"
     ]
    }
   ],
   "source": [
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train, test_size=0.2, stratify=y_train)\n",
    "\n",
    "n_timesteps, n_outputs, n_features = X_train_cnn.shape[1], len(np.unique(y_train_cnn)), 1 \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "cnn = build_simple_cnn(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1, 100)            200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 100)            400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 100)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 150)            15150     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 150)            600       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 150)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 150)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 200)            30200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 200)            800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 47,752\n",
      "Trainable params: 46,852\n",
      "Non-trainable params: 900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train_cnn.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6514 samples, validate on 1629 samples\n",
      "Epoch 1/50\n",
      "6514/6514 [==============================] - 5s 828us/step - loss: 0.2289 - accuracy: 0.9477 - val_loss: 0.3620 - val_accuracy: 0.9650\n",
      "Epoch 2/50\n",
      "6514/6514 [==============================] - 3s 415us/step - loss: 0.1131 - accuracy: 0.9642 - val_loss: 0.0854 - val_accuracy: 0.9687\n",
      "Epoch 3/50\n",
      "6514/6514 [==============================] - 3s 406us/step - loss: 0.1170 - accuracy: 0.9647 - val_loss: 0.0774 - val_accuracy: 0.9693\n",
      "Epoch 4/50\n",
      "6514/6514 [==============================] - 2s 349us/step - loss: 0.1227 - accuracy: 0.9609 - val_loss: 0.0777 - val_accuracy: 0.9711\n",
      "Epoch 5/50\n",
      "6514/6514 [==============================] - 3s 399us/step - loss: 0.1063 - accuracy: 0.9678 - val_loss: 0.0756 - val_accuracy: 0.9718\n",
      "Epoch 6/50\n",
      "6514/6514 [==============================] - 2s 336us/step - loss: 0.1094 - accuracy: 0.9647 - val_loss: 0.0770 - val_accuracy: 0.9742\n",
      "Epoch 7/50\n",
      "6514/6514 [==============================] - 2s 379us/step - loss: 0.1019 - accuracy: 0.9675 - val_loss: 0.0731 - val_accuracy: 0.9736\n",
      "Epoch 8/50\n",
      "6514/6514 [==============================] - 2s 314us/step - loss: 0.1001 - accuracy: 0.9662 - val_loss: 0.0726 - val_accuracy: 0.9742\n",
      "Epoch 9/50\n",
      "6514/6514 [==============================] - 3s 386us/step - loss: 0.1059 - accuracy: 0.9653 - val_loss: 0.0769 - val_accuracy: 0.9761\n",
      "Epoch 10/50\n",
      "6514/6514 [==============================] - 2s 309us/step - loss: 0.1049 - accuracy: 0.9648 - val_loss: 0.0838 - val_accuracy: 0.9791\n",
      "Epoch 11/50\n",
      "6514/6514 [==============================] - 2s 299us/step - loss: 0.1086 - accuracy: 0.9633 - val_loss: 0.0883 - val_accuracy: 0.9742\n",
      "Epoch 12/50\n",
      "6514/6514 [==============================] - 2s 305us/step - loss: 0.1077 - accuracy: 0.9648 - val_loss: 0.0756 - val_accuracy: 0.9761\n",
      "Epoch 13/50\n",
      "6514/6514 [==============================] - 2s 333us/step - loss: 0.0963 - accuracy: 0.9671 - val_loss: 0.0693 - val_accuracy: 0.9797\n",
      "Epoch 14/50\n",
      "6514/6514 [==============================] - 3s 388us/step - loss: 0.1030 - accuracy: 0.9658 - val_loss: 0.0730 - val_accuracy: 0.9761\n",
      "Epoch 15/50\n",
      "6514/6514 [==============================] - 3s 398us/step - loss: 0.1016 - accuracy: 0.9664 - val_loss: 0.0896 - val_accuracy: 0.9791\n",
      "Epoch 16/50\n",
      "6514/6514 [==============================] - 2s 348us/step - loss: 0.1000 - accuracy: 0.9650 - val_loss: 0.0744 - val_accuracy: 0.9761\n",
      "Epoch 17/50\n",
      "6514/6514 [==============================] - 3s 392us/step - loss: 0.1037 - accuracy: 0.9632 - val_loss: 0.0691 - val_accuracy: 0.9791\n",
      "Epoch 18/50\n",
      "6514/6514 [==============================] - 2s 356us/step - loss: 0.1001 - accuracy: 0.9644 - val_loss: 0.0769 - val_accuracy: 0.9791\n",
      "Epoch 19/50\n",
      "6514/6514 [==============================] - 2s 372us/step - loss: 0.0992 - accuracy: 0.9655 - val_loss: 0.0698 - val_accuracy: 0.9797\n",
      "Epoch 20/50\n",
      "6514/6514 [==============================] - 2s 346us/step - loss: 0.0980 - accuracy: 0.9670 - val_loss: 0.0670 - val_accuracy: 0.9791\n",
      "Epoch 21/50\n",
      "6514/6514 [==============================] - 2s 337us/step - loss: 0.0901 - accuracy: 0.9690 - val_loss: 0.0678 - val_accuracy: 0.9791\n",
      "Epoch 22/50\n",
      "6514/6514 [==============================] - 2s 349us/step - loss: 0.0981 - accuracy: 0.9678 - val_loss: 0.0626 - val_accuracy: 0.9810\n",
      "Epoch 23/50\n",
      "6514/6514 [==============================] - 2s 362us/step - loss: 0.1009 - accuracy: 0.9662 - val_loss: 0.0790 - val_accuracy: 0.9767\n",
      "Epoch 24/50\n",
      "6514/6514 [==============================] - 2s 381us/step - loss: 0.0984 - accuracy: 0.9662 - val_loss: 0.0718 - val_accuracy: 0.9791\n",
      "Epoch 25/50\n",
      "6514/6514 [==============================] - 3s 403us/step - loss: 0.0934 - accuracy: 0.9693 - val_loss: 0.0686 - val_accuracy: 0.9791\n",
      "Epoch 26/50\n",
      "6514/6514 [==============================] - 2s 308us/step - loss: 0.0951 - accuracy: 0.9687 - val_loss: 0.0704 - val_accuracy: 0.9816\n",
      "Epoch 27/50\n",
      "6514/6514 [==============================] - 3s 523us/step - loss: 0.0972 - accuracy: 0.9665 - val_loss: 0.0641 - val_accuracy: 0.9865\n",
      "Epoch 28/50\n",
      "6514/6514 [==============================] - 3s 489us/step - loss: 0.0902 - accuracy: 0.9696 - val_loss: 0.0596 - val_accuracy: 0.9877\n",
      "Epoch 29/50\n",
      "6514/6514 [==============================] - 3s 452us/step - loss: 0.0900 - accuracy: 0.9699 - val_loss: 0.0650 - val_accuracy: 0.9871\n",
      "Epoch 30/50\n",
      "6514/6514 [==============================] - 3s 443us/step - loss: 0.0904 - accuracy: 0.9688 - val_loss: 0.0547 - val_accuracy: 0.9877\n",
      "Epoch 31/50\n",
      "6514/6514 [==============================] - 3s 471us/step - loss: 0.0937 - accuracy: 0.9687 - val_loss: 0.0642 - val_accuracy: 0.9804\n",
      "Epoch 32/50\n",
      "6514/6514 [==============================] - 3s 405us/step - loss: 0.0925 - accuracy: 0.9695 - val_loss: 0.0508 - val_accuracy: 0.9914\n",
      "Epoch 33/50\n",
      "6514/6514 [==============================] - 3s 397us/step - loss: 0.0928 - accuracy: 0.9693 - val_loss: 0.0675 - val_accuracy: 0.9816\n",
      "Epoch 34/50\n",
      "6514/6514 [==============================] - 3s 446us/step - loss: 0.0923 - accuracy: 0.9678 - val_loss: 0.0553 - val_accuracy: 0.9859\n",
      "Epoch 35/50\n",
      "6514/6514 [==============================] - 3s 447us/step - loss: 0.0891 - accuracy: 0.9708 - val_loss: 0.0577 - val_accuracy: 0.9822\n",
      "Epoch 36/50\n",
      "6514/6514 [==============================] - 3s 401us/step - loss: 0.0899 - accuracy: 0.9705 - val_loss: 0.0574 - val_accuracy: 0.9871\n",
      "Epoch 37/50\n",
      "6514/6514 [==============================] - 3s 425us/step - loss: 0.0914 - accuracy: 0.9685 - val_loss: 0.0604 - val_accuracy: 0.9883\n",
      "Epoch 38/50\n",
      "6514/6514 [==============================] - 2s 381us/step - loss: 0.0891 - accuracy: 0.9714 - val_loss: 0.0556 - val_accuracy: 0.9865\n",
      "Epoch 39/50\n",
      "6514/6514 [==============================] - 3s 399us/step - loss: 0.0846 - accuracy: 0.9725 - val_loss: 0.0534 - val_accuracy: 0.9914\n",
      "Epoch 40/50\n",
      "6514/6514 [==============================] - 3s 419us/step - loss: 0.0860 - accuracy: 0.9737 - val_loss: 0.0519 - val_accuracy: 0.9914\n",
      "Epoch 41/50\n",
      "6514/6514 [==============================] - 3s 406us/step - loss: 0.0869 - accuracy: 0.9713 - val_loss: 0.0543 - val_accuracy: 0.9932\n",
      "Epoch 42/50\n",
      "6514/6514 [==============================] - 2s 377us/step - loss: 0.0894 - accuracy: 0.9710 - val_loss: 0.0583 - val_accuracy: 0.9926\n",
      "Epoch 43/50\n",
      "6514/6514 [==============================] - 3s 415us/step - loss: 0.0851 - accuracy: 0.9731 - val_loss: 0.0527 - val_accuracy: 0.9939\n",
      "Epoch 44/50\n",
      "6514/6514 [==============================] - 3s 416us/step - loss: 0.0910 - accuracy: 0.9701 - val_loss: 0.0544 - val_accuracy: 0.9939\n",
      "Epoch 45/50\n",
      "6514/6514 [==============================] - 2s 344us/step - loss: 0.0835 - accuracy: 0.9737 - val_loss: 0.0523 - val_accuracy: 0.9939\n",
      "Epoch 46/50\n",
      "6514/6514 [==============================] - 3s 439us/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 0.0500 - val_accuracy: 0.9932\n",
      "Epoch 47/50\n",
      "6514/6514 [==============================] - 3s 411us/step - loss: 0.0864 - accuracy: 0.9718 - val_loss: 0.0495 - val_accuracy: 0.9939\n",
      "Epoch 48/50\n",
      "6514/6514 [==============================] - 2s 345us/step - loss: 0.0863 - accuracy: 0.9719 - val_loss: 0.0539 - val_accuracy: 0.9932\n",
      "Epoch 49/50\n",
      "6514/6514 [==============================] - 2s 342us/step - loss: 0.0828 - accuracy: 0.9730 - val_loss: 0.0474 - val_accuracy: 0.9920\n",
      "Epoch 50/50\n",
      "6514/6514 [==============================] - 2s 322us/step - loss: 0.0858 - accuracy: 0.9713 - val_loss: 0.0537 - val_accuracy: 0.9932\n"
     ]
    }
   ],
   "source": [
    "history_cnn = cnn.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9786116322701689\n",
      "F1-score [0.98290855 0.97142857]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      1693\n",
      "           1       0.95      1.00      0.97       972\n",
      "\n",
      "    accuracy                           0.98      2665\n",
      "   macro avg       0.97      0.98      0.98      2665\n",
      "weighted avg       0.98      0.98      0.98      2665\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1639,   54],\n",
       "       [   3,  969]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn.predict(X_test_cnn), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2665/2665 [==============================] - 0s 56us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10201171497756696, 0.9786116480827332]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(n_timesteps, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(n_timesteps, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = build_lstm(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6514/6514 [==============================] - 2s 303us/step - loss: 0.0844 - accuracy: 0.9730\n",
      "Epoch 2/20\n",
      " 544/6514 [=>............................] - ETA: 1s - loss: 0.0893 - accuracy: 0.9651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6514/6514 [==============================] - 3s 410us/step - loss: 0.0841 - accuracy: 0.9724\n",
      "Epoch 3/20\n",
      "6514/6514 [==============================] - 2s 361us/step - loss: 0.0877 - accuracy: 0.9716\n",
      "Epoch 4/20\n",
      "6514/6514 [==============================] - 3s 385us/step - loss: 0.0830 - accuracy: 0.9725\n",
      "Epoch 5/20\n",
      "6514/6514 [==============================] - 2s 292us/step - loss: 0.0829 - accuracy: 0.9722\n",
      "Epoch 6/20\n",
      "6514/6514 [==============================] - 2s 288us/step - loss: 0.0825 - accuracy: 0.9733\n",
      "Epoch 7/20\n",
      "6514/6514 [==============================] - 2s 307us/step - loss: 0.0828 - accuracy: 0.9730\n",
      "Epoch 8/20\n",
      "6514/6514 [==============================] - 2s 350us/step - loss: 0.0872 - accuracy: 0.9724\n",
      "Epoch 9/20\n",
      "6514/6514 [==============================] - 3s 459us/step - loss: 0.0875 - accuracy: 0.9719\n",
      "Epoch 10/20\n",
      "6514/6514 [==============================] - 3s 523us/step - loss: 0.0869 - accuracy: 0.9710\n",
      "Epoch 11/20\n",
      "6514/6514 [==============================] - 3s 509us/step - loss: 0.0840 - accuracy: 0.9724\n",
      "Epoch 12/20\n",
      "6514/6514 [==============================] - 3s 419us/step - loss: 0.0835 - accuracy: 0.9750\n",
      "Epoch 13/20\n",
      "6514/6514 [==============================] - 2s 376us/step - loss: 0.0851 - accuracy: 0.9722\n",
      "Epoch 14/20\n",
      "6514/6514 [==============================] - 2s 353us/step - loss: 0.0746 - accuracy: 0.9762\n",
      "Epoch 15/20\n",
      "6514/6514 [==============================] - 3s 419us/step - loss: 0.0823 - accuracy: 0.9745\n",
      "Epoch 16/20\n",
      "6514/6514 [==============================] - 3s 436us/step - loss: 0.0768 - accuracy: 0.9748\n",
      "Epoch 17/20\n",
      "6514/6514 [==============================] - 2s 347us/step - loss: 0.0804 - accuracy: 0.9730\n",
      "Epoch 18/20\n",
      "6514/6514 [==============================] - 2s 369us/step - loss: 0.0795 - accuracy: 0.9747\n",
      "Epoch 19/20\n",
      "6514/6514 [==============================] - 3s 399us/step - loss: 0.0799 - accuracy: 0.9750\n",
      "Epoch 20/20\n",
      "6514/6514 [==============================] - 2s 353us/step - loss: 0.0818 - accuracy: 0.9731\n"
     ]
    }
   ],
   "source": [
    "history_lstm = cnn.fit(X_train_cnn, y_train_cnn, epochs=20, batch_size=mini_batch_size, callbacks=callbacks).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9707317073170731\n",
      "F1-score [0.9764208  0.96142433]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98      1693\n",
      "           1       0.93      1.00      0.96       972\n",
      "\n",
      "    accuracy                           0.97      2665\n",
      "   macro avg       0.96      0.98      0.97      2665\n",
      "weighted avg       0.97      0.97      0.97      2665\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1615,   78],\n",
       "       [   0,  972]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(lstm.predict(X_test_cnn), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2665/2665 [==============================] - 0s 147us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6389276894798422, 0.9707317352294922]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.evaluate(X_test_cnn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyts.datasets import load_basic_motions\n",
    "\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tslearn/preprocessing.py:179: RuntimeWarning: invalid value encountered in true_divide\n",
      "  X_ = nomin / range_t + self.value_range[0]\n"
     ]
    }
   ],
   "source": [
    "scaler = TimeSeriesScalerMinMax()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  1\n",
      "N. LABELS:  2\n",
      "N. FEATURES:  1\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_outputs, n_features = X_train.shape[1], len(np.unique(y_train)), X_train.shape[2] \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)\n",
    "print(\"N. FEATURES: \", n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time Serie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPool2D, Flatten, Dropout, LeakyReLU, GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm2(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(n_timesteps, n_features), return_sequences=True, \n",
    "                        kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    #1\n",
    "    for _ in range(2):\n",
    "        model.add(LSTM(4, kernel_initializer='TruncatedNormal', return_sequences=True))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.04))   \n",
    "\n",
    "    #2\n",
    "    model.add(LSTM(32, kernel_initializer='TruncatedNormal', return_sequences=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.7))\n",
    "    \n",
    "    #3\n",
    "    for _ in range(2):\n",
    "        model.add(Dense(256, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.2))\n",
    "    #4\n",
    "    for _ in range(1):\n",
    "        model.add(Dense(64, kernel_initializer='TruncatedNormal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Dropout(0.7))\n",
    "\n",
    "    #5\n",
    "    model.add(Dense(32, kernel_initializer='TruncatedNormal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "        \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2 = build_lstm2(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 1, 4)              96        \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1, 4)              16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1, 4)              144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 4)              16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 4)              144       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 4)              16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 100,562\n",
      "Trainable params: 99,258\n",
      "Non-trainable params: 1,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_lstm2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6514 samples, validate on 1629 samples\n",
      "Epoch 1/20\n",
      "6514/6514 [==============================] - 11s 2ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 2/20\n",
      "6514/6514 [==============================] - 7s 1ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 3/20\n",
      "6514/6514 [==============================] - 9s 1ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 4/20\n",
      "6514/6514 [==============================] - 9s 1ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 5/20\n",
      "6514/6514 [==============================] - 6s 930us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 6/20\n",
      "6514/6514 [==============================] - 6s 846us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 7/20\n",
      "6514/6514 [==============================] - 6s 860us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 8/20\n",
      "6514/6514 [==============================] - 7s 1ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 9/20\n",
      "6514/6514 [==============================] - 5s 799us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 10/20\n",
      "6514/6514 [==============================] - 8s 1ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 11/20\n",
      "6514/6514 [==============================] - 7s 1ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 12/20\n",
      "6514/6514 [==============================] - 6s 972us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 13/20\n",
      "6514/6514 [==============================] - 12s 2ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 14/20\n",
      "6514/6514 [==============================] - 7s 1ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 15/20\n",
      "6514/6514 [==============================] - 6s 916us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 16/20\n",
      "6514/6514 [==============================] - 5s 767us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 17/20\n",
      "6514/6514 [==============================] - 6s 941us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 18/20\n",
      "6514/6514 [==============================] - 6s 859us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 19/20\n",
      "6514/6514 [==============================] - 9s 1ms/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 20/20\n",
      "6514/6514 [==============================] - 5s 818us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n"
     ]
    }
   ],
   "source": [
    "history_lstm2 = lstm2.fit(X_train_cnn, y_train_cnn, epochs=20, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                          validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6352720450281426\n",
      "F1-score [0.77696191 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78      1693\n",
      "           1       0.00      0.00      0.00       972\n",
      "\n",
      "    accuracy                           0.64      2665\n",
      "   macro avg       0.32      0.50      0.39      2665\n",
      "weighted avg       0.40      0.64      0.49      2665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1693,    0],\n",
       "       [ 972,    0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(lstm2.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn3(n_timesteps, n_outputs, n_features):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=1, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = build_cnn3(n_timesteps, n_outputs, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "mc = ModelCheckpoint('best_model_cnn2.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "callbacks = [rlr, mc]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6514 samples, validate on 1629 samples\n",
      "Epoch 1/20\n",
      "6514/6514 [==============================] - 3s 505us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 2/20\n",
      "6514/6514 [==============================] - 2s 295us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 3/20\n",
      "6514/6514 [==============================] - 2s 361us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 4/20\n",
      "6514/6514 [==============================] - 3s 489us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 5/20\n",
      "6514/6514 [==============================] - 2s 294us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 6/20\n",
      "6514/6514 [==============================] - 2s 325us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 7/20\n",
      "6514/6514 [==============================] - 2s 377us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 8/20\n",
      "6514/6514 [==============================] - 2s 355us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 9/20\n",
      "6514/6514 [==============================] - 2s 330us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 10/20\n",
      "6514/6514 [==============================] - 2s 351us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 11/20\n",
      "6514/6514 [==============================] - 2s 320us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 12/20\n",
      "6514/6514 [==============================] - 2s 351us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 13/20\n",
      "6514/6514 [==============================] - 2s 370us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 14/20\n",
      "6514/6514 [==============================] - 2s 264us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 15/20\n",
      "6514/6514 [==============================] - 2s 326us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 16/20\n",
      "6514/6514 [==============================] - 2s 301us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 17/20\n",
      "6514/6514 [==============================] - 2s 262us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 18/20\n",
      "6514/6514 [==============================] - 2s 289us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 19/20\n",
      "6514/6514 [==============================] - 2s 264us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n",
      "Epoch 20/20\n",
      "6514/6514 [==============================] - 2s 258us/step - loss: nan - accuracy: 0.7877 - val_loss: nan - val_accuracy: 0.7876\n"
     ]
    }
   ],
   "source": [
    "history_cnn3 = cnn3.fit(X_train_cnn, y_train_cnn, epochs=20, batch_size=mini_batch_size, callbacks=callbacks,\n",
    "                      validation_data=(X_val_cnn, y_val_cnn)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6352720450281426\n",
      "F1-score [0.77696191 0.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78      1693\n",
      "           1       0.00      0.00      0.00       972\n",
      "\n",
      "    accuracy                           0.64      2665\n",
      "   macro avg       0.32      0.50      0.39      2665\n",
      "weighted avg       0.40      0.64      0.49      2665\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1693,    0],\n",
       "       [ 972,    0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(cnn3.predict(X_test), axis=1)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
