{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset \n",
    "df=pd.read_csv(\"/home/umair/Desktop/Data Science and BI/data mining/occupancy_data/DataCleaned.csv\")\n",
    "test=pd.read_csv(\"/home/umair/Desktop/Data Science and BI/data mining/occupancy_data/DataCleanedTest.csv\")\n",
    "test2=pd.read_csv(\"/home/umair/Desktop/Data Science and BI/data mining/occupancy_data/DataCleanedTest2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the useless column\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace =True)\n",
    "df.drop(['date'], axis=1, inplace =True)\n",
    "df.drop(['DayName'], axis=1, inplace =True)\n",
    "\n",
    "test.drop(['Unnamed: 0'], axis=1, inplace =True)\n",
    "test.drop(['date'], axis=1, inplace =True)\n",
    "test.drop(['DayName'], axis=1, inplace =True)\n",
    "\n",
    "test2.drop(['Unnamed: 0'], axis=1, inplace =True)\n",
    "test2.drop(['date'], axis=1, inplace =True)\n",
    "test2.drop(['DayName'], axis=1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the two datasets splitting the attributes with the class and selecting the right attributes\n",
    "attributes = [col for col in df.columns if col != 'Occupancy']\n",
    "X_train = df[attributes]\n",
    "y_train = df['Occupancy']\n",
    "\n",
    "attributes = [col for col in test.columns if col != 'Occupancy']\n",
    "X_test = test[attributes]\n",
    "y_test = test['Occupancy']\n",
    "\n",
    "attributes = [col for col in test2.columns if col != 'Occupancy']\n",
    "X_test2 = test2[attributes]\n",
    "y_test2 = test2['Occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('IsWorkDay', 'Hour', 'IsWorkHour', 'Temperature', 'Humidity', 'Light', 'CO2')\n",
      "===================================\n",
      "Best parameters set:\n",
      "{'alpha': 0.0001, 'penalty': 'l2', 'random_state': 0, 'tol': 0.1}\n",
      "\n",
      "Accuracy 0.918580375782881\n",
      "\n",
      "Train Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      6414\n",
      "           1       0.74      0.95      0.83      1729\n",
      "\n",
      "    accuracy                           0.92      8143\n",
      "   macro avg       0.86      0.93      0.89      8143\n",
      "weighted avg       0.93      0.92      0.92      8143\n",
      "\n",
      "\n",
      "Train Confusion Matrix:\n",
      "[[5834  580]\n",
      " [  83 1646]]\n",
      "\n",
      "Accuracy 0.8424015009380863\n",
      "\n",
      "Test1 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.77      0.86      1693\n",
      "           1       0.71      0.96      0.82       972\n",
      "\n",
      "    accuracy                           0.84      2665\n",
      "   macro avg       0.84      0.87      0.84      2665\n",
      "weighted avg       0.88      0.84      0.85      2665\n",
      "\n",
      "\n",
      "Test1 Confusion Matrix:\n",
      "[[1309  384]\n",
      " [  36  936]]\n",
      "\n",
      "Accuracy 0.5841878589007383\n",
      "\n",
      "Test2 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.53      0.67      7703\n",
      "           1       0.31      0.78      0.44      2049\n",
      "\n",
      "    accuracy                           0.58      9752\n",
      "   macro avg       0.60      0.66      0.55      9752\n",
      "weighted avg       0.78      0.58      0.62      9752\n",
      "\n",
      "\n",
      "Test2 Confusion Matrix:\n",
      "[[4100 3603]\n",
      " [ 452 1597]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#HyperTuning parameters with GridSearch crossing between training set, test set1\n",
    "# and test set2. Searching for the best C\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "features_combs_list = [\n",
    "    ('IsWorkDay', 'Hour', 'IsWorkHour', 'Temperature', 'Humidity', 'Light', 'CO2')\n",
    "]\n",
    "\n",
    "hyper_params_space = [\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'random_state': [0],\n",
    "        'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 5],\n",
    "        'tol': 0.\n",
    "    },\n",
    "]\n",
    "\n",
    "for features in features_combs_list:\n",
    "    print(features)\n",
    "    print('===================================')\n",
    "    X = X_train\n",
    "    X_t1 = X_test\n",
    "    X_t2 = X_test2\n",
    "\n",
    "    svc = GridSearchCV(Perceptron(), hyper_params_space,\n",
    "                       scoring='accuracy')\n",
    "    svc.fit(X, y_train)\n",
    "    \n",
    "    print('Best parameters set:')\n",
    "    print(svc.best_params_)\n",
    "    print()\n",
    "    \n",
    "    preds = [\n",
    "        (svc.predict(X), y_train, 'Train'),\n",
    "        (svc.predict(X_t1), y_test, 'Test1'),\n",
    "        (svc.predict(X_t2), y_test2, 'Test2')\n",
    "    ]\n",
    "    \n",
    "    for pred in preds:\n",
    "        print('Accuracy %s' % accuracy_score(pred[1], pred[0]))\n",
    "        print()\n",
    "        print(pred[2] + ' Classification Report:')\n",
    "        print()\n",
    "        print(classification_report(pred[1], pred[0]))\n",
    "        print()\n",
    "        print(pred[2] + ' Confusion Matrix:')\n",
    "        print(confusion_matrix(pred[1], pred[0]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
