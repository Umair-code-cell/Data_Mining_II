{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset \n",
    "df=pd.read_csv(\"/home/umair/Desktop/Data Science and BI/data mining/occupancy_data/DataCleaned.csv\")\n",
    "test=pd.read_csv(\"/home/umair/Desktop/Data Science and BI/data mining/occupancy_data/DataCleanedTest.csv\")\n",
    "test2=pd.read_csv(\"/home/umair/Desktop/Data Science and BI/data mining/occupancy_data/DataCleanedTest2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the useless column\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace =True)\n",
    "df.drop(['date'], axis=1, inplace =True)\n",
    "df.drop(['DayName'], axis=1, inplace =True)\n",
    "\n",
    "test.drop(['Unnamed: 0'], axis=1, inplace =True)\n",
    "test.drop(['date'], axis=1, inplace =True)\n",
    "test.drop(['DayName'], axis=1, inplace =True)\n",
    "\n",
    "test2.drop(['Unnamed: 0'], axis=1, inplace =True)\n",
    "test2.drop(['date'], axis=1, inplace =True)\n",
    "test2.drop(['DayName'], axis=1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the two datasets splitting the attributes with the class and selecting the right attributes\n",
    "attributes = [col for col in df.columns if \n",
    "              col == 'IsWorkDay' \n",
    "              or col == 'Hour' \n",
    "              or col == 'Light'\n",
    "              or col == 'IsWorkHour'\n",
    "              or col == 'Temperature' \n",
    "              or col == 'Humidity'\n",
    "              or col == 'CO2'\n",
    "              or col == 'HumidityRatio'\n",
    "             ]\n",
    "X_train = df[attributes].values\n",
    "y_train = df['Occupancy']\n",
    "\n",
    "attributes = [col for col in df.columns if \n",
    "              col == 'IsWorkDay' \n",
    "              or col == 'Hour' \n",
    "              or col == 'Light'\n",
    "              or col == 'IsWorkHour'\n",
    "              or col == 'Temperature' \n",
    "              or col == 'Humidity'\n",
    "              or col == 'CO2'\n",
    "              or col == 'HumidityRatio'\n",
    "             ]\n",
    "X_test = test[attributes].values\n",
    "y_test = test['Occupancy']\n",
    "\n",
    "attributes = [col for col in test2.columns if col != 'Occupancy']\n",
    "X_test2 = test2[attributes].values\n",
    "y_test2 = test2['Occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoid the warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization of the datasets using the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test2 = scaler.fit_transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('IsWorkDay', 'Hour', 'IsWorkHour', 'Temperature', 'Humidity', 'Light', 'CO2')\n",
      "===================================\n",
      "Best parameters set:\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Accuracy 0.9882107331450325\n",
      "\n",
      "Train Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      6414\n",
      "           1       0.95      0.99      0.97      1729\n",
      "\n",
      "    accuracy                           0.99      8143\n",
      "   macro avg       0.98      0.99      0.98      8143\n",
      "weighted avg       0.99      0.99      0.99      8143\n",
      "\n",
      "\n",
      "Train Confusion Matrix:\n",
      "[[6328   86]\n",
      " [  10 1719]]\n",
      "\n",
      "Accuracy 0.6352720450281426\n",
      "\n",
      "Test1 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78      1693\n",
      "           1       0.00      0.00      0.00       972\n",
      "\n",
      "    accuracy                           0.64      2665\n",
      "   macro avg       0.32      0.50      0.39      2665\n",
      "weighted avg       0.40      0.64      0.49      2665\n",
      "\n",
      "\n",
      "Test1 Confusion Matrix:\n",
      "[[1693    0]\n",
      " [ 972    0]]\n",
      "\n",
      "Accuracy 0.9932321575061526\n",
      "\n",
      "Test2 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      7703\n",
      "           1       0.97      0.99      0.98      2049\n",
      "\n",
      "    accuracy                           0.99      9752\n",
      "   macro avg       0.99      0.99      0.99      9752\n",
      "weighted avg       0.99      0.99      0.99      9752\n",
      "\n",
      "\n",
      "Test2 Confusion Matrix:\n",
      "[[7649   54]\n",
      " [  12 2037]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#HyperTuning parameters with GridSearch of the kernel=linear crossing between training set, test set1\n",
    "# and test set 2. Searching for the best C\n",
    "features_combs_list = [\n",
    "    ('IsWorkDay', 'Hour', 'IsWorkHour', 'Temperature', 'Humidity', 'Light', 'CO2')\n",
    "]\n",
    "\n",
    "hyper_params_space = [\n",
    "    {\n",
    "        'kernel': ['linear'],\n",
    "        'C': np.arange(0.1, 5, 0.1)\n",
    "    },\n",
    "]\n",
    "\n",
    "for features in features_combs_list:\n",
    "    print(features)\n",
    "    print('===================================')\n",
    "    X = X_train\n",
    "    X_t1 = X_test\n",
    "    X_t2 = X_test2\n",
    "\n",
    "    svc = GridSearchCV(SVC(), hyper_params_space,\n",
    "                       scoring='accuracy')\n",
    "    svc.fit(X, y_train)\n",
    "    \n",
    "    print('Best parameters set:')\n",
    "    print(svc.best_params_)\n",
    "    print()\n",
    "    \n",
    "    preds = [\n",
    "        (svc.predict(X), y_train, 'Train'),\n",
    "        (svc.predict(X_t1), y_test, 'Test1'),\n",
    "        (svc.predict(X_t2), y_test2, 'Test2')\n",
    "    ]\n",
    "    \n",
    "    for pred in preds:\n",
    "        print('Accuracy %s' % accuracy_score(pred[1], pred[0]))\n",
    "        print()\n",
    "        print(pred[2] + ' Classification Report:')\n",
    "        print()\n",
    "        print(classification_report(pred[1], pred[0]))\n",
    "        print()\n",
    "        print(pred[2] + ' Confusion Matrix:')\n",
    "        print(confusion_matrix(pred[1], pred[0]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('IsWorkDay', 'Hour', 'IsWorkHour', 'Temperature', 'Humidity', 'Light', 'CO2')\n",
      "===================================\n",
      "Best parameters set:\n",
      "{'gamma': 0.1, 'kernel': 'rbf'}\n",
      "\n",
      "Accuracy 0.9885791477342503\n",
      "\n",
      "Train Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      6414\n",
      "           1       0.95      0.99      0.97      1729\n",
      "\n",
      "    accuracy                           0.99      8143\n",
      "   macro avg       0.98      0.99      0.98      8143\n",
      "weighted avg       0.99      0.99      0.99      8143\n",
      "\n",
      "\n",
      "Train Confusion Matrix:\n",
      "[[6333   81]\n",
      " [  12 1717]]\n",
      "\n",
      "Accuracy 0.9613508442776736\n",
      "\n",
      "Test1 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1693\n",
      "           1       0.95      0.94      0.95       972\n",
      "\n",
      "    accuracy                           0.96      2665\n",
      "   macro avg       0.96      0.96      0.96      2665\n",
      "weighted avg       0.96      0.96      0.96      2665\n",
      "\n",
      "\n",
      "Test1 Confusion Matrix:\n",
      "[[1648   45]\n",
      " [  58  914]]\n",
      "\n",
      "Accuracy 0.9932321575061526\n",
      "\n",
      "Test2 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      7703\n",
      "           1       0.97      0.99      0.98      2049\n",
      "\n",
      "    accuracy                           0.99      9752\n",
      "   macro avg       0.99      0.99      0.99      9752\n",
      "weighted avg       0.99      0.99      0.99      9752\n",
      "\n",
      "\n",
      "Test2 Confusion Matrix:\n",
      "[[7649   54]\n",
      " [  12 2037]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#HyperTuning parameters with GridSearch of the kernel=rbf crossing between training set, test set1\n",
    "# and test set 2. Searching for the best gamma\n",
    "features_combs_list = [\n",
    "    ('IsWorkDay', 'Hour', 'IsWorkHour', 'Temperature', 'Humidity', 'Light', 'CO2')\n",
    "]\n",
    "\n",
    "hyper_params_space = [\n",
    "    #{\n",
    "    #    'kernel': ['linear'],\n",
    "    #    'C': [0.1, 1, 10, 50, 100]\n",
    "    #},\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': np.arange(0.1, 5, 0.1)\n",
    "    },\n",
    "]\n",
    "\n",
    "for features in features_combs_list:\n",
    "    print(features)\n",
    "    print('===================================')\n",
    "    X = X_train\n",
    "    X_t1 = X_test\n",
    "    X_t2 = X_test2\n",
    "\n",
    "    svc = GridSearchCV(SVC(), hyper_params_space,\n",
    "                       scoring='accuracy')\n",
    "    svc.fit(X, y_train)\n",
    "    \n",
    "    print('Best parameters set:')\n",
    "    print(svc.best_params_)\n",
    "    print()\n",
    "    \n",
    "    preds = [\n",
    "        (svc.predict(X), y_train, 'Train'),\n",
    "        (svc.predict(X_t1), y_test, 'Test1'),\n",
    "        (svc.predict(X_t2), y_test2, 'Test2')\n",
    "    ]\n",
    "    \n",
    "    for pred in preds:\n",
    "        print('Accuracy %s' % accuracy_score(pred[1], pred[0]))\n",
    "        print()\n",
    "        print(pred[2] + ' Classification Report:')\n",
    "        print()\n",
    "        print(classification_report(pred[1], pred[0]))\n",
    "        print()\n",
    "        print(pred[2] + ' Confusion Matrix:')\n",
    "        print(confusion_matrix(pred[1], pred[0]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('IsWorkDay', 'Hour', 'IsWorkHour', 'Temperature', 'Humidity', 'Light', 'CO2')\n",
      "===================================\n",
      "Best parameters set:\n",
      "{'degree': 4, 'gamma': 8, 'kernel': 'poly'}\n",
      "\n",
      "Accuracy 0.9964386589708952\n",
      "\n",
      "Train Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6414\n",
      "           1       0.99      1.00      0.99      1729\n",
      "\n",
      "    accuracy                           1.00      8143\n",
      "   macro avg       0.99      1.00      0.99      8143\n",
      "weighted avg       1.00      1.00      1.00      8143\n",
      "\n",
      "\n",
      "Train Confusion Matrix:\n",
      "[[6392   22]\n",
      " [   7 1722]]\n",
      "\n",
      "Accuracy 0.8056285178236398\n",
      "\n",
      "Test1 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1693\n",
      "           1       1.00      0.47      0.64       972\n",
      "\n",
      "    accuracy                           0.81      2665\n",
      "   macro avg       0.88      0.73      0.75      2665\n",
      "weighted avg       0.85      0.81      0.78      2665\n",
      "\n",
      "\n",
      "Test1 Confusion Matrix:\n",
      "[[1693    0]\n",
      " [ 518  454]]\n",
      "\n",
      "Accuracy 0.7005742411812962\n",
      "\n",
      "Test2 Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.66      0.78      7703\n",
      "           1       0.40      0.85      0.54      2049\n",
      "\n",
      "    accuracy                           0.70      9752\n",
      "   macro avg       0.67      0.76      0.66      9752\n",
      "weighted avg       0.83      0.70      0.73      9752\n",
      "\n",
      "\n",
      "Test2 Confusion Matrix:\n",
      "[[5092 2611]\n",
      " [ 309 1740]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#HyperTuning parameters with GridSearch of the kernel=poly crossing between training set, test set1\n",
    "# and test set 2. Searching for the best gamma and degree\n",
    "features_combs_list = [\n",
    "    ('IsWorkDay', 'Hour', 'IsWorkHour', 'Temperature', 'Humidity', 'Light', 'CO2')\n",
    "]\n",
    "\n",
    "hyper_params_space = [\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'gamma': np.arange(1, 10),\n",
    "        'degree': [4]\n",
    "    },\n",
    "]\n",
    "\n",
    "for features in features_combs_list:\n",
    "    print(features)\n",
    "    print('===================================')\n",
    "    X = X_train\n",
    "    X_t1 = X_test\n",
    "    X_t2 = X_test2\n",
    "\n",
    "    svc = GridSearchCV(SVC(), hyper_params_space,\n",
    "                       scoring='accuracy')\n",
    "    svc.fit(X, y_train)\n",
    "    \n",
    "    print('Best parameters set:')\n",
    "    print(svc.best_params_)\n",
    "    print()\n",
    "    \n",
    "    preds = [\n",
    "        (svc.predict(X), y_train, 'Train'),\n",
    "        (svc.predict(X_t1), y_test, 'Test1'),\n",
    "        (svc.predict(X_t2), y_test2, 'Test2')\n",
    "    ]\n",
    "    \n",
    "    for pred in preds:\n",
    "        print('Accuracy %s' % accuracy_score(pred[1], pred[0]))\n",
    "        print()\n",
    "        print(pred[2] + ' Classification Report:')\n",
    "        print()\n",
    "        print(classification_report(pred[1], pred[0]))\n",
    "        print()\n",
    "        print(pred[2] + ' Confusion Matrix:')\n",
    "        print(confusion_matrix(pred[1], pred[0]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
